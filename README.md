# Streams-Redirection-Pipeline

One of the critical things in data science is to transform raw data before data cleaning. To perform basic functional operations such as looking up for certain words in rows, word counts, row & column counts, sorting or filtering, we can leverage **pipeline** in Linux shells or Unix terminal.

## Concepts

There are three key concepts of building data pipelines in Linux:

- Streams
- Redirection
- Pipe

To fully understand key concepts, see [examples](https://github.com/HaotianPeterGong/Streams-Redirection-Pipeline/blob/main/Codes/Stream_Redirection-Code_Demonstration.ipynb) in Jupyter Notebook.

## Data Example

After learning concepts, we would use [SuperstoreSales](https://github.com/HaotianPeterGong/Streams-Redirection-Pipeline/tree/main/Data), which has 8400 record lines of order, customer, and product information, to train in a real-world scenario. Functions like sort, unique, and character manipulation are practiced.

## Codes
The [.ipynb](https://github.com/HaotianPeterGong/Streams-Redirection-Pipeline/blob/main/Codes/Stream_Redirection-Code_Demonstration.ipynb) file shows codes with output printing. You can also copy commands from the [.txt](https://github.com/HaotianPeterGong/Streams-Redirection-Pipeline/blob/main/Codes/Stream_Redirection-Code_Demonstration.txt) file, and test on your laptop terminal. Please put the csv file into an appropriate path for testing.
